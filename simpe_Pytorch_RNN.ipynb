{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Basic Pytorch RNN model\n"
      ],
      "metadata": {
        "id": "nZQRfdNxyQ3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://download.pytorch.org/tutorial/data.zip; unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL_lM5QhyQhN",
        "outputId": "9cdeccd7-1091-44e1-89be-ef9cd5c2d093"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 2814k  100 2814k    0     0  11.0M      0 --:--:-- --:--:-- --:--:-- 11.0M\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMdLBpnB2VvT",
        "outputId": "1775a518-c6a4-4a6c-ee44-f2d3e951e406"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U4XLPgFXx6d9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from string import ascii_letters\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from unidecode import unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = torch.manual_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "5qIR2cFS2LZ0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/data/names\"\n",
        "\n",
        "lang2label = {\n",
        "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long) for i, file_name in enumerate(os.listdir(data_dir))\n",
        "}"
      ],
      "metadata": {
        "id": "I5Zwrygd2oqK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ8qFqgh3MSa",
        "outputId": "b8812785-986a-4a99-f948-1f0a1b46c5ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Russian': tensor([0]),\n",
              " 'Japanese': tensor([1]),\n",
              " 'Greek': tensor([2]),\n",
              " 'Italian': tensor([3]),\n",
              " 'Czech': tensor([4]),\n",
              " 'Dutch': tensor([5]),\n",
              " 'English': tensor([6]),\n",
              " 'Polish': tensor([7]),\n",
              " 'French': tensor([8]),\n",
              " 'Irish': tensor([9]),\n",
              " 'Chinese': tensor([10]),\n",
              " 'Korean': tensor([11]),\n",
              " 'Vietnamese': tensor([12]),\n",
              " 'Portuguese': tensor([13]),\n",
              " 'Spanish': tensor([14]),\n",
              " 'Arabic': tensor([15]),\n",
              " 'German': tensor([16]),\n",
              " 'Scottish': tensor([17])}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_langs = len(lang2label)"
      ],
      "metadata": {
        "id": "HA_o_cFr3OsP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "6unbyDR73kmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unidecode('Ślusàrski')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pOjlscWB3Z94",
        "outputId": "c8413ad1-047e-438d-e993-65d5b9df2e01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Slusarski'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = { letter: i for i, letter in enumerate(ascii_letters + \" .,:;-'\")}\n",
        "\n",
        "num_letters  = len(char2idx)\n",
        "num_letters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skprWscW3pe5",
        "outputId": "ec8ae54f-86a3-4114-b703-8443f2141f09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "character vocabulary"
      ],
      "metadata": {
        "id": "WWO315jK4PWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SGJ49uj4F9Y",
        "outputId": "9adb5076-25e1-4dc8-818a-411ef314a3b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 0,\n",
              " 'b': 1,\n",
              " 'c': 2,\n",
              " 'd': 3,\n",
              " 'e': 4,\n",
              " 'f': 5,\n",
              " 'g': 6,\n",
              " 'h': 7,\n",
              " 'i': 8,\n",
              " 'j': 9,\n",
              " 'k': 10,\n",
              " 'l': 11,\n",
              " 'm': 12,\n",
              " 'n': 13,\n",
              " 'o': 14,\n",
              " 'p': 15,\n",
              " 'q': 16,\n",
              " 'r': 17,\n",
              " 's': 18,\n",
              " 't': 19,\n",
              " 'u': 20,\n",
              " 'v': 21,\n",
              " 'w': 22,\n",
              " 'x': 23,\n",
              " 'y': 24,\n",
              " 'z': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " ' ': 52,\n",
              " '.': 53,\n",
              " ',': 54,\n",
              " ':': 55,\n",
              " ';': 56,\n",
              " '-': 57,\n",
              " \"'\": 58}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating tensor"
      ],
      "metadata": {
        "id": "W9doH8dp4W4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def name2tensor(name):\n",
        "  tensor = torch.zeros(len(name), 1, num_letters)   # for rnn tensor would be (seq_len, batch_Size, input_size)\n",
        "\n",
        "  for i, char in enumerate(name):\n",
        "    tensor[i][0][char2idx[char]] =1\n",
        "\n",
        "  return tensor"
      ],
      "metadata": {
        "id": "AsBpAauL4Ig3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name2tensor(\"abc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWQ7cB0q4yZX",
        "outputId": "9775fa06-74f5-48b2-d3ac-680b7e315c50"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation"
      ],
      "metadata": {
        "id": "E12s426F5Kuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_names = []\n",
        "target_langs = []\n",
        "\n",
        "for file in os.listdir(data_dir):\n",
        "  with open(os.path.join(data_dir, file)) as f:\n",
        "    lang = file.split(\".\")[0]\n",
        "    names = [unidecode(line.rstrip()) for line in f]\n",
        "    for name in names:\n",
        "      try:\n",
        "        tensor_names.append(name2tensor(name))\n",
        "        target_langs.append(lang2label[lang])\n",
        "      except KeyError:\n",
        "        pass"
      ],
      "metadata": {
        "id": "Sf46n8lC5GR4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djrcn2of53AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    range(len(target_langs)),\n",
        "    test_size = 0.2,\n",
        "    shuffle=True,\n",
        "    stratify = target_langs\n",
        ")\n",
        "\n",
        "train_dataset = [\n",
        "    (tensor_names[i], target_langs[i]) for i in train_idx\n",
        "\n",
        "]\n",
        "\n",
        "test_dataset = [\n",
        "    (tensor_names[i], target_langs[i]) for i in test_idx\n",
        "]"
      ],
      "metadata": {
        "id": "y3sTSyO46Dkz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train: {len(train_dataset)}\")\n",
        "print(f\"Test: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TAUZPKn6525",
        "outputId": "abc7b9bb-0a09-45d6-dcc8-1e023bf19a85"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 16056\n",
            "Test: 4014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Jd4T_Zrk7M9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "XRM4QzlG87Ct"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang_RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(Lang_RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.in2output = nn.Linear(input_size + hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, hidden_state):\n",
        "    combined = torch.cat((x, hidden_state), 1)\n",
        "    hidden = torch.sigmoid(self.in2hidden(combined))\n",
        "    output = self.in2output(combined)\n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "      return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))"
      ],
      "metadata": {
        "id": "LTY68OsW7LWF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVsTArkO8xSN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Lang_RNN(num_letters, hidden_size, num_langs)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "eEo3M1OX9DPq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "PiwH-gjJ9m4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "print_interval = 3000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  random.shuffle(train_dataset)\n",
        "\n",
        "  for i, (name, label) in enumerate(train_dataset):\n",
        "\n",
        "    hidden_state = model.init_hidden()\n",
        "    for char in name:\n",
        "      output, hidden_state = model(char, hidden_state)\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % print_interval == 0:\n",
        "      print(\n",
        "          f\" Epoch [{epoch + 1}/{num_epochs}], \"\n",
        "          f\" Step [{i + 1}/{len(train_dataset)}], \"\n",
        "          f\" Loss {loss.item():.4f}\"\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZRrgf_A9ioA",
        "outputId": "3b0d59af-b4c3-4e72-ffea-bd4a0d77af68"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch [1/2],  Step [3000/16056],  Loss 0.4571\n",
            " Epoch [1/2],  Step [6000/16056],  Loss 0.0262\n",
            " Epoch [1/2],  Step [9000/16056],  Loss 1.7313\n",
            " Epoch [1/2],  Step [12000/16056],  Loss 2.6222\n",
            " Epoch [1/2],  Step [15000/16056],  Loss 4.6921\n",
            " Epoch [2/2],  Step [3000/16056],  Loss 3.7604\n",
            " Epoch [2/2],  Step [6000/16056],  Loss 0.0002\n",
            " Epoch [2/2],  Step [9000/16056],  Loss 0.0942\n",
            " Epoch [2/2],  Step [12000/16056],  Loss 0.0090\n",
            " Epoch [2/2],  Step [15000/16056],  Loss 0.0392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model\n"
      ],
      "metadata": {
        "id": "QyHcqdfI_5ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "num_samples = len(test_dataset)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for name, label in test_dataset:\n",
        "    hidden_state = model.init_hidden()\n",
        "    for char in name:\n",
        "      output, hidden_state = model(char, hidden_state)\n",
        "    _, pred = torch.max(output, dim=1)\n",
        "    num_correct += bool(pred == label)\n",
        "\n",
        "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8Tgzgbe--CR",
        "outputId": "30411e98-eff2-4410-ee5a-f8d87600a41b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 71.5994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2lang = {label.item(): lang for lang, label in lang2label.items()}\n",
        "\n",
        "def myrnn_predict(name):\n",
        "    model.eval()\n",
        "    tensor_name = name2tensor(name)\n",
        "    with torch.no_grad():\n",
        "        hidden_state = model.init_hidden()\n",
        "        for char in tensor_name:\n",
        "            output, hidden_state = model(char, hidden_state)\n",
        "        _, pred = torch.max(output, dim=1)\n",
        "    model.train()\n",
        "    return label2lang[pred.item()]"
      ],
      "metadata": {
        "id": "cUztm8CCAlNy"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myrnn_predict(\"Mike\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "L5DSgI6ZENQf",
        "outputId": "16adfc84-d109-4fc8-a90f-de1dfd483195"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GRUModel.forward() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-1badf56e6538>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyrnn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mike\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-2b6f114577d2>\u001b[0m in \u001b[0;36mmyrnn_predict\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: GRUModel.forward() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU ( gated Recurrent Unit)"
      ],
      "metadata": {
        "id": "H4Hph1NmBBN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F3BRNiMMBBDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAm2LHxMBOjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "jNhVoRMUBPX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, num_layers, hidden_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=num_letters,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, num_langs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden_state = self.init_hidden()\n",
        "        output, hidden_state = self.gru(x, hidden_state)\n",
        "        output = self.fc(output[-1])\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size).to(device)"
      ],
      "metadata": {
        "id": "_0WpcOeXBN6V"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRUModel(num_layers=2, hidden_size=hidden_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "CUyPZKh1BYIs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    random.shuffle(train_dataset)\n",
        "    for i, (name, label) in enumerate(train_dataset):\n",
        "        output = model(name)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % print_interval == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
        "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
        "                f\"Loss: {loss.item():.4f}\"\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0rz_PbtBa4Z",
        "outputId": "b2416cf9-2945-4f7f-b584-c695361cf98e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [3000/16056], Loss: 0.0040\n",
            "Epoch [1/2], Step [6000/16056], Loss: 0.2934\n",
            "Epoch [1/2], Step [9000/16056], Loss: 0.0779\n",
            "Epoch [1/2], Step [12000/16056], Loss: 0.0063\n",
            "Epoch [1/2], Step [15000/16056], Loss: 0.0058\n",
            "Epoch [2/2], Step [3000/16056], Loss: 0.6708\n",
            "Epoch [2/2], Step [6000/16056], Loss: 0.6056\n",
            "Epoch [2/2], Step [9000/16056], Loss: 2.9235\n",
            "Epoch [2/2], Step [12000/16056], Loss: 0.1928\n",
            "Epoch [2/2], Step [15000/16056], Loss: 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for name, label in test_dataset:\n",
        "        output = model(name)\n",
        "        _, pred = torch.max(output, dim=1)\n",
        "        num_correct += bool(pred == label)\n",
        "\n",
        "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44xvsrkuBdFh",
        "outputId": "01e00702-55d0-43c3-9e4c-1dcb14292a61"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.7673%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pytorch_predict(name):\n",
        "    model.eval()\n",
        "    tensor_name = name2tensor(name)\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor_name)\n",
        "        _, pred = torch.max(output, dim=1)\n",
        "    model.train()\n",
        "    return label2lang[pred.item()]"
      ],
      "metadata": {
        "id": "hDQ-NAw-DbU3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_predict(\"Jake\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JFE09r_ADiqG",
        "outputId": "08d4bcc9-8301-4ba2-e6e4-f766eee5b33c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Russian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4DjpUKUIDwba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}